{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU6Cw-2MOVWE"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Tuana BayazÄ±t\n",
        "# byztuana@gmail.com\n",
        "# ================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib\n",
        "\n",
        "df = pd.read_excel(\"Talent_Academy_Case_DT_2025.xlsx\")\n",
        "\n",
        "print(\"Before removing duplicates:\", df.shape)\n",
        "df = df.drop_duplicates()\n",
        "print(\"After removing duplicates:\", df.shape)\n",
        "df = df.drop(columns=[\"HastaNo\"])\n",
        "\n",
        "initial_num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "initial_cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "df[initial_num_cols] = num_imputer.fit_transform(df[initial_num_cols])\n",
        "\n",
        "df[initial_cat_cols] = df[initial_cat_cols].fillna('Unknown')\n",
        "\n",
        "if 'Cinsiyet' in df.columns and df['Cinsiyet'].nunique() == 2:\n",
        "    le = LabelEncoder()\n",
        "    df['Cinsiyet_enc'] = le.fit_transform(df['Cinsiyet'])\n",
        "\n",
        "multi_cat_cols = ['KanGrubu', 'Uyruk', 'Bolum']\n",
        "df = pd.get_dummies(df, columns=[col for col in multi_cat_cols if col in df.columns], drop_first=True)\n",
        "\n",
        "\n",
        "for col in ['KronikHastalik', 'Alerji', 'Tanilar']:\n",
        "    if col in df.columns:\n",
        "        # Top 10 frequent items for each column\n",
        "        top_items = pd.Series([item for sublist in df[col].dropna().apply(lambda x: str(x).split(',')) for item in sublist]).value_counts().head(10).index\n",
        "        for item in top_items:\n",
        "            df[f\"{col}_{item.strip()}\"] = df[col].apply(lambda x: 1 if pd.notnull(x) and item in str(x) else 0)\n",
        "\n",
        "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "X = df.drop(columns=[\"TedaviSuresi\"])\n",
        "y = df[\"TedaviSuresi\"]\n",
        "\n",
        "cols_to_drop_from_X = ['KronikHastalik', 'Alerji', 'Tanilar']\n",
        "X = X.drop(columns=[col for col in cols_to_drop_from_X if col in X.columns])\n",
        "\n",
        "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "df.to_csv(\"preprocessed_case_study.csv\", index=False)\n",
        "print(\"Preprocessed CSV saved: preprocessed_case_study.csv\")\n",
        "\n",
        "# Optional: Create preprocessing pipeline for future modeling\n",
        "num_pipeline = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"num\", num_pipeline, num_cols),\n",
        "    (\"cat\", cat_pipeline, cat_cols)\n",
        "])\n",
        "\n",
        "preprocessor.fit(X)\n",
        "joblib.dump(preprocessor, \"preprocessor.joblib\")\n",
        "print(\"Preprocessor pipeline saved: preprocessor.joblib\")\n",
        "\n",
        "df.head()\n",
        "df.info()\n",
        "\n"
      ]
    }
  ]
}